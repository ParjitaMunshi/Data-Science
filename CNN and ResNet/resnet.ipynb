{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03bae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f008d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training parameters\n",
    "data_augmentation = True\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0dafabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6d8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many layers? Depends on the model version\n",
    "def model_depth(version,n=3):\n",
    "    \"\"\"\n",
    "    Computes depth from supplied model parameter n\n",
    "    \"\"\"\n",
    "    if version == 1:\n",
    "        depth = n * 6 + 2\n",
    "    elif version == 2:\n",
    "        depth = n * 9 + 2\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ae91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_type(version,n):\n",
    "    # Model name, depth and version\n",
    "    model_type = 'ResNet%dv%d' % (model_depth(version,n), version)\n",
    "    return model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffa2f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet29v2\n"
     ]
    }
   ],
   "source": [
    "model_t = model_type(2,3)\n",
    "print(model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a517b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show any data\n",
    "def show_data(sample):\n",
    "    \"\"\"\n",
    "    Shows the given sample data as an image\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(sample)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b2cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f192b70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_data(x_train[250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b7a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8f7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb345b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "    \n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6ec1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4079cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for auto-scaling learning based on epochs\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d5dff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function of a single ResNet layer\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abb61168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet Version 1 model builder\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "     # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed628ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet Version 2 model builder\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "         for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            num_filters_in = num_filters_out\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "355b2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_model(version=1):\n",
    "    \"\"\"\n",
    "    Chooses the model based on version\n",
    "    \n",
    "    # Argument:\n",
    "        An (int) version number (1 or 2)\n",
    "    # Returns:\n",
    "        keras model\n",
    "    \"\"\"\n",
    "    if version == 2:\n",
    "        model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "    else:\n",
    "        model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f00f4bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3a33f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = model_depth(version=version,n=n)\n",
    "model = choose_model(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d11fad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet20v1\n"
     ]
    }
   ],
   "source": [
    "print(model_type(version,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "560ca134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 16)   448         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 16)   2320        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 16)   0           ['activation[0][0]',             \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 16)   0           ['activation_2[0][0]',           \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 16)   0           ['activation_4[0][0]',           \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 32)   4640        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parjita\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_7 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 32)   9248        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 32)   544         ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 16, 32)   0           ['conv2d_9[0][0]',               \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 32)   0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 32)  128         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 16, 32)   0           ['activation_8[0][0]',           \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 32)   0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  128         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 32)  128         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 16, 32)   0           ['activation_10[0][0]',          \n",
      "                                                                  'batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 32)   0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 64)     18496       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 64)    256         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 64)     2112        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 64)    256         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 64)     0           ['conv2d_16[0][0]',              \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 64)     0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 64)    256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 8, 8, 64)    256         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 8, 64)     0           ['activation_14[0][0]',          \n",
      "                                                                  'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8, 8, 64)     0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 8, 64)    256         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 8, 64)     0           ['activation_16[0][0]',          \n",
      "                                                                  'batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 8, 8, 64)     0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 64)    0           ['activation_18[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           650         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27f79504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Prepare model saving directory\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "733db8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "#Prepare callbacks for model saving and for learning rate adjustment\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             period=3\n",
    "                            )\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66b2add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, we will not save the models, so won't include the `checkpoint` in the `callbacks`\n",
    "callbacks = [lr_reducer, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc422a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 696s 440ms/step - loss: 1.4858 - accuracy: 0.5226 - val_loss: 1.4802 - val_accuracy: 0.5274 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 513s 328ms/step - loss: 1.0763 - accuracy: 0.6704 - val_loss: 1.0867 - val_accuracy: 0.6754 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 485s 310ms/step - loss: 0.9176 - accuracy: 0.7334 - val_loss: 1.0808 - val_accuracy: 0.6906 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "from time import time\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 3\n",
    "t1 = time()\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "t2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77fa202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of 3 epochs took 28.27 minutes total.\n"
     ]
    }
   ],
   "source": [
    "time_delta=round((t2-t1)/60,2)\n",
    "\n",
    "print (\"Training of {} epochs took {} minutes total.\".format(epochs, time_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8da99d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 29s 92ms/step - loss: 1.0808 - accuracy: 0.6906\n",
      "Test loss: 1.0807651281356812\n",
      "Test accuracy: 0.6905999779701233\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "991fcbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "391/391 [==============================] - 401s 1s/step - loss: 2.0886 - accuracy: 0.3372 - val_loss: 1.9056 - val_accuracy: 0.3750\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 486s 1s/step - loss: 1.6123 - accuracy: 0.4713 - val_loss: 1.5440 - val_accuracy: 0.4943\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 449s 1s/step - loss: 1.4729 - accuracy: 0.5239 - val_loss: 1.4573 - val_accuracy: 0.5292\n"
     ]
    }
   ],
   "source": [
    "#A smaller learning rate and larger batch size\n",
    "version = 1\n",
    "n = 3\n",
    "\n",
    "depth = model_depth(version=version,n=n)\n",
    "model = choose_model(version)\n",
    "# Hard coding the learning rate = 1e-4\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
    "epochs = 3\n",
    "# Note, we turn off the callbacks as we want to use the new learning rate\n",
    "t1 = time()\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "t2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7842b963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of 3 epochs took 22.29 minutes total.\n"
     ]
    }
   ],
   "source": [
    "time_delta=round((t2-t1)/60,2)\n",
    "\n",
    "print (\"Training of {} epochs took {} minutes total.\".format(epochs, time_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be274cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 26s 84ms/step - loss: 1.4573 - accuracy: 0.5292\n",
      "Test loss: 1.4573472738265991\n",
      "Test accuracy: 0.52920001745224\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e5a3a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: ResNet26v1\n",
      "There are, in total, 372330 parameters in this model!\n"
     ]
    }
   ],
   "source": [
    "#More variation and longer training...\n",
    "version = 1\n",
    "n = 4\n",
    "\n",
    "depth = model_depth(version=version,n=n)\n",
    "model = choose_model(version)\n",
    "\n",
    "print(\"Model type:\",model_type(version,n))\n",
    "print(\"There are, in total, {} parameters in this model!\".format(model.count_params()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ddb6983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parjita\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Hard coding the learning rate = 1e-3\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-3),\n",
    "              metrics=['accuracy'])\n",
    "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
    "epochs = 3\n",
    "callbacks = [lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bd42cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "391/391 [==============================] - 629s 2s/step - loss: 1.6577 - accuracy: 0.4706 - val_loss: 1.8276 - val_accuracy: 0.4546 - lr: 0.0010\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 534s 1s/step - loss: 1.1939 - accuracy: 0.6406 - val_loss: 1.3943 - val_accuracy: 0.5742 - lr: 0.0010\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 526s 1s/step - loss: 0.9815 - accuracy: 0.7179 - val_loss: 1.7796 - val_accuracy: 0.5082 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Note, we turn off the callbacks as we want to use the new learning rate\n",
    "t1 = time()\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "t2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c3f2a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of 3 epochs took 28.2 minutes total.\n"
     ]
    }
   ],
   "source": [
    "time_delta=round((t2-t1)/60,2)\n",
    "\n",
    "print (\"Training of {} epochs took {} minutes total.\".format(epochs, time_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d185e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 32s 101ms/step - loss: 1.7796 - accuracy: 0.5082\n",
      "Test loss: 1.779614806175232\n",
      "Test accuracy: 0.5081999897956848\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de55b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
